Silent Speech Recognition: Automatic Lip Reading Model Using 3D CNN and GRU

Project Overview The Silent Speech Recognition: Automatic Lip Reading Model Using 3D CNN and GRU project is an innovative initiative aimed at developing a cutting-edge system that can accurately recognize and interpret silent speech by analyzing lip movements. By leveraging the combined power of 3D Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU), this project aims to process and interpret dynamic visual cues from lip movements to achieve high-performance silent speech recognition.

DATASET - https://drive.google.com/drive/folders/1eIU9gEJh3TcQuRz5yLISTrhn7WWm2aZr?usp=drive_link

Technologies and Tools:

Programming Languages - Python

Libraries and Framework - TensorFlow,openCV,NumPy,Matplotlib,Imageio,gdown

Hardware - GPU

Developement Environment - Jupyter/colab notebook or VSCode

Project Purpose

The primary goal of this project is to harness advanced artificial intelligence techniques for silent speech recognition, with several impactful applications:

Accessibility Enhancement: Assist individuals with hearing impairments by providing a means to understand spoken language through lip movement analysis.

Communication in Noisy Environments: Offer an alternative communication method in noisy settings where traditional speech recognition fails.

Integration with Virtual Assistants: Enhance interactions with virtual assistants like IBM Watson, improving robustness in voice-based communication.

Telecommunications: Improve communication in poor audio quality scenarios.

Security Systems: Utilize lip movement analysis for identifying unauthorized individuals.

Project Architecture

Approach

Data Collection: Collect a diverse dataset featuring individuals speaking various phrases silently while capturing their lip movements.

Data Preprocessing: Extract frames from videos, align lip movements, and prepare training and testing datasets.

Model Development: Develop a deep learning model using 3D CNN to capture spatiotemporal features and GRU to understand sequential speech patterns.

Training and Validation: Train the model on the dataset and validate its performance using appropriate metrics.

Integration: Create a user-friendly interface for interacting with the model, suitable for targeted applications.

Testing and Optimization: Test the system in real-world scenarios, fine-tune the model, and optimize performance.

Deployment: Deploy the model for practical use in applications like accessibility tools, communication devices, and security systems.
