{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **`INSTALL AND IMPORT LIBRARIES`**"
      ],
      "metadata": {
        "id": "RBcr2TqON54j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "SpYM_7IQNQXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install opencv-python matplotlib imageio gdown tensorflow"
      ],
      "metadata": {
        "id": "ctJ5ubzeNywN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio"
      ],
      "metadata": {
        "id": "4RP71FT7N0ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "id": "NDXon7sRN2FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "4EK5Q_xZN3oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`CREATE AND BUILD DATA`**"
      ],
      "metadata": {
        "id": "sC3o5G_iN__L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown"
      ],
      "metadata": {
        "id": "-cbhM28NOF8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'your_dataset.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "IUUPMQWSOJRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video(path:str) -> List[float]:\n",
        "\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        ret, frame = cap.read()\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "        frames.append(frame[190:236,80:220,:])\n",
        "    cap.release()\n",
        "\n",
        "    mean = tf.math.reduce_mean(frames)\n",
        "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "    return tf.cast((frames - mean), tf.float32) / std"
      ],
      "metadata": {
        "id": "l_0WH0J6OK4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
      ],
      "metadata": {
        "id": "xJMo7aqBQRpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
        ")"
      ],
      "metadata": {
        "id": "3EWO0RAzQTe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num.get_vocabulary()"
      ],
      "metadata": {
        "id": "wBCuoUCTQVa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num(['n','i','c','k'])"
      ],
      "metadata": {
        "id": "w57i111PQbOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char([14,  9,  3, 11])"
      ],
      "metadata": {
        "id": "cxo7Sw4NQbu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_alignments(path:str) -> List[str]:\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens,' ',line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
      ],
      "metadata": {
        "id": "6Wn3gpjcQc2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path: str):\n",
        "    path = bytes.decode(path.numpy())\n",
        "    file_name = path.split('\\\\')[-1].split('.')[0]\n",
        "    video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
        "    alignment_path = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "\n",
        "    return frames, alignments"
      ],
      "metadata": {
        "id": "eimRZX6uQeV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '.\\\\data\\\\s1\\\\bbal6n.mpg'"
      ],
      "metadata": {
        "id": "of3yB6KAQhIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('\\\\')[-1].split('.')[0]"
      ],
      "metadata": {
        "id": "b6X-f4AFQjER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames, alignments = load_data(tf.convert_to_tensor(test_path))"
      ],
      "metadata": {
        "id": "5sL0fdD6QkYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(frames[40])"
      ],
      "metadata": {
        "id": "vu3jxn-FQmHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alignments"
      ],
      "metadata": {
        "id": "jMqg8GRTQnrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])"
      ],
      "metadata": {
        "id": "tJdH-HgMQpAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mappable_function(path:str) ->List[str]:\n",
        "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
        "    return result"
      ],
      "metadata": {
        "id": "WrWhl2SnQqPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`DATA PREPROCESSING`**"
      ],
      "metadata": {
        "id": "TdXm8pEIQwVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "X-HUmJyaQuxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
        "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
        "data = data.map(mappable_function)\n",
        "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
        "data = data.prefetch(tf.data.AUTOTUNE)\n",
        "train = data.take(450)\n",
        "test = data.skip(450)"
      ],
      "metadata": {
        "id": "tkVJ4wNMQ-pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "id": "ITYzlD5cRA3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames, alignments = data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "QnVzJ5ZbRCuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(frames)"
      ],
      "metadata": {
        "id": "z11cJDGKRFAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "Gab4FecRRGdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = sample.next(); val[0]"
      ],
      "metadata": {
        "id": "gFZsi_RNRH2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(val[0][0][35])"
      ],
      "metadata": {
        "id": "QAh91dWmRLU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])"
      ],
      "metadata": {
        "id": "kgVzq94XRNAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`DEEP NEURAL NETWORKS`**"
      ],
      "metadata": {
        "id": "cwYdCRTMRO2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
      ],
      "metadata": {
        "id": "fUOECH7bRVPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.as_numpy_iterator().next()[0][0].shape"
      ],
      "metadata": {
        "id": "bqpeWN0dRW9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(256, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(75, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
      ],
      "metadata": {
        "id": "x_atMkazRYZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "d6nuKjPWRat4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(val[0])"
      ],
      "metadata": {
        "id": "3fS5CmqmRcVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
      ],
      "metadata": {
        "id": "FQfch5lBRefA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in yhat[0]])"
      ],
      "metadata": {
        "id": "kJTXCyQvRfn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.input_shape"
      ],
      "metadata": {
        "id": "3DNiZKtpRh1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.output_shape"
      ],
      "metadata": {
        "id": "GgOZjs0dRiOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`TRAINING AND TESTING`**"
      ],
      "metadata": {
        "id": "WI2WdBtSRlIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch < 30:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)"
      ],
      "metadata": {
        "id": "48DT2TD_RuDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "7LedME7nRwi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProduceExample(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, dataset) -> None:\n",
        "        self.dataset = dataset.as_numpy_iterator()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
        "        data = self.dataset.next()\n",
        "        yhat = self.model.predict(data[0])\n",
        "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
        "        for x in range(len(yhat)):\n",
        "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
        "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
        "            print('~'*100)"
      ],
      "metadata": {
        "id": "OQ9pEchwRykP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss=CTCLoss)"
      ],
      "metadata": {
        "id": "-aLg7u8KR1nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)"
      ],
      "metadata": {
        "id": "fwiIrObuR4bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_callback = LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "TgEtSRK5R6RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_callback = ProduceExample(test)"
      ],
      "metadata": {
        "id": "O2Fq8HCYR883"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train, validation_data=test, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
      ],
      "metadata": {
        "id": "BHhY3mlZR_GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`PREDICTION`**"
      ],
      "metadata": {
        "id": "oVdD_MH6SCJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'your_dataset.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "LgCMUOHISHhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('models/checkpoint')"
      ],
      "metadata": {
        "id": "g8xhuwtUSKTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "XGuyjGeaSLh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = test_data.next()"
      ],
      "metadata": {
        "id": "E6-mvQAWSNwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(sample[0])"
      ],
      "metadata": {
        "id": "vqri2MA7SQUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('~'*100, 'REAL TEXT')\n",
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
      ],
      "metadata": {
        "id": "nANTJA9aSR78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
      ],
      "metadata": {
        "id": "e2ZTsbEnSTRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('~'*100, 'PREDICTIONS')\n",
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
      ],
      "metadata": {
        "id": "Uc_s1yrJSU0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}